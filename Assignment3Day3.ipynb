{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "import string\n", "def rangeof():\n", "    return random.randint(3, 10)\n", "with open(\"Ques1.txt\",\"w\") as file:\n", "    str = string.ascii_letters\n", "    for i in range(999):\n", "        randoms = ''.join(random.choices(str,k=rangeof()))\n", "        file.write(randoms+'\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["checking = open(\"Ques1.txt\",\"r\")\n", "count=0\n", "temp = '1'\n", "while temp!='':\n", "    temp=checking.readline()\n", "    print(temp)\n", "    count+=1\n", "print(count)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "import string"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(\"Ques2.txt\", \"w\") as file:\n", "    alphabet = string.ascii_letters\n", "    for i in range(50000):\n", "        randoms = ''.join(random.choices(alphabet, k=100))\n", "        file.write(randoms + '\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "file_path = r'C:\\Users\\prave\\OneDrive\\Desktop\\Summer School\\Ques2.txt'\n", "print(os.path.getsize(file_path))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues3"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "import string\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for file_num in range(1, 11):\n", "    file_name = f\"Ques3_{file_num}.txt\"\n", "    file_path = os.path.join(r'C:\\Users\\prave\\OneDrive\\Desktop\\Summer School', file_name)\n", "    with open(file_path, \"w\") as file:\n", "        alphabet = string.ascii_letters\n", "        for i in range(50000):\n", "            randoms = ''.join(random.choices(alphabet, k=100))\n", "            file.write(randoms + '\\n')\n", "    print(f\"{file_name} created. Size: {os.path.getsize(file_path)} bytes.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues4"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "import string\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def Createfiles(loopvalue, filename):\n", "    with open(filename, \"w\") as file:\n", "        alphabet = string.ascii_letters\n", "        for i in range(loopvalue):\n", "            randoms = ''.join(random.choices(alphabet, k=1000))\n", "            file.write(randoms + '\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_file_size(file_path):\n", "    return os.path.getsize(file_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loopvalues = [1000000, 2000000, 3000000, 4000000, 5000000]\n", "file_num = 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for value in loopvalues:\n", "    file_name = f\"Ques4_{file_num}.txt\"\n", "    Createfiles(value, file_name)\n", "    file_path = r'C:\\Users\\prave\\OneDrive\\Desktop\\Summer School\\Ques4_{}.txt'.format(file_num)\n", "    file_size = get_file_size(file_path)\n", "    print(f\"{file_name} created. Size: {file_size} bytes.\")\n", "    file_num += 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_to_uppercase(filename):\n", "    with open(filename, \"r+\") as file:\n", "        content = file.read()\n", "        new_content = content.upper()\n", "        file.seek(0)\n", "        file.write(new_content)\n", "        file.truncate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["files = [\"Ques4_1.txt\", \"Ques4_2.txt\", \"Ques4_3.txt\", \"Ques4_4.txt\", \"Ques4_5.txt\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in files:\n", "    convert_to_uppercase(filename)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues6"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from threading import *\n", "from time import sleep"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FileThread(Thread):\n", "    def __init__(self, filename):\n", "        super().__init__()\n", "        self.filename = filename\n", "    def run(self):\n", "        with open(self.filename, \"r+\") as file:\n", "            content = file.read()\n", "            new_content = content.upper()\n", "            file.seek(0)  # Move the file pointer to the beginning\n", "            file.write(new_content)\n", "            file.truncate()  # Remove any remaining content if new_content is shorter\n", "            sleep(2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create instances of the thread for each file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["files = [\"Ques4_1.txt\", \"Ques4_2.txt\", \"Ques4_3.txt\", \"Ques4_4.txt\", \"Ques4_5.txt\"]\n", "threads = [FileThread(filename) for filename in files]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Start all threads"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for thread in threads:\n", "    thread.start()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wait for all threads to finish"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for thread in threads:\n", "    thread.join()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues7"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from google_images_download import google_images_download"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["response = google_images_download.googleimagesdownload()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["search_query = \"cat\"\n", "arguments = {\"keywords\": search_query, \"limit\":10, \"format\": \"jpg\"}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["response.download(arguments)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues8 "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pytube import YouTube"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def download_machine_learning_videos(search_query, num_videos):\n", "    query = search_query + \" tutorial\"  # Adding \"tutorial\" to get more educational videos.\n", "    video = YouTube.search(query, limit=num_videos)\n", "    for v in video:\n", "        try:\n", "            stream_now = v.streams.filter(file_extension=\"mp4\", progressive=True).first()\n", "            if stream:\n", "                video_title = v.title\n", "                print(f\"Downloading '{video_title}'...\")\n", "                stream.download(output_path=\"videos\")\n", "                print(f\"Video '{video_title}' downloaded successfully!\")\n", "        except Exception as e:\n", "            print(f\"Error occurred while downloading video: {str(e)}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    search_query = \"Machine Learning\"\n", "    num_videos = 10\n", "    download_machine_learning_videos(search_query, num_videos)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues9 import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from moviepy.video.io.VideoFileClip import VideoFileClip"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def audio(video_path):\n", "    try:\n", "        video_clip = VideoFileClip(video_path)\n", "        audio_clip = video_clip.audio\n", "        audio_filename = os.path.splitext(os.path.basename(video_path))[0] + \".mp3\"\n", "        audio_clip.write_audiofile(audio_filename)\n", "        print(f\"Audio extracted from '{video_path}' and saved as '{audio_filename}'\")\n", "        audio_clip.close()\n", "        video_clip.close()\n", "    except Exception as e:\n", "        print(f\"Error occurred while converting video to audio: {str(e)}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    video_folder = \"videos\"\n", "    \n", "    video_files = [f for f in os.listdir(video_folder) if f.endswith(\".mp4\")]\n", "    for video_file in video_files:\n", "        video_path = os.path.join(video_folder, video_file)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues11"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import threading\n", "from google_images_download import google_images_download\n", "from PIL import Image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def download(keyword, num_images, output_folder):\n", "    response = google_images_download.googleimagesdownload()\n", "    arguments = {\n", "        \"keywords\": keyword,\n", "        \"limit\": num_images,\n", "        \"print_urls\": True,\n", "        \"output_directory\": output_folder\n", "    }\n", "    try:\n", "        paths = response.download(arguments)\n", "        print(\"Images downloaded successfully!\")\n", "    except Exception as e:\n", "        print(f\"Error occurred: {str(e)}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def rescale(image_path, output_folder, scale_percent):\n", "    try:\n", "        img = Image.open(image_path)\n", "        width, height = img.size\n", "        new_width = int(width * scale_percent / 100)\n", "        new_height = int(height * scale_percent / 100)\n", "        resized_img = img.resize((new_width, new_height))\n", "        new_image_path = os.path.join(output_folder, os.path.basename(image_path))\n", "        resized_img.save(new_image_path)\n", "        print(f\"Image '{os.path.basename(image_path)}' rescaled to 50% and saved as '{os.path.basename(new_image_path)}'\")\n", "    except Exception as e:\n", "        print(f\"Error occurred while rescaling image: {str(e)}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process(image_path, output_folder, scale_percent):\n", "    rescale(image_path, output_folder, scale_percent)\n", "    os.remove(image_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    keyword = \"Dog\"\n", "    num_images = 500\n", "    output_folder = \"images\"\n", "    scale_percent = 50\n", "    num_threads = 10\n\n", "    # Create the output folder if it doesn't exist\n", "    os.makedirs(output_folder, exist_ok=True)\n\n", "    # Create a list to hold the thread objects\n", "    threads = []\n", "    download(keyword, num_images, output_folder)\n\n", "    # Get a list of all image files in the 'images' folder\n", "    image_files = [f for f in os.listdir(output_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n", "    for image_file in image_files:\n", "        image_path = os.path.join(output_folder, image_file)\n\n", "        # Create a thread for each image and start it\n", "        thread = threading.Thread(target=process, args=(image_path, output_folder, scale_percent))\n", "        thread.start()\n", "        threads.append(thread)\n\n", "        # Wait for a certain number of threads to finish before starting the next batch\n", "        if len(threads) >= num_threads:\n", "            for thread in threads:\n", "                thread.join()\n", "            threads = []\n\n", "    # Wait for any remaining threads to finish\n", "    for thread in threads:\n", "        thread.join()\n", "    print(\"All images downloaded and rescaled successfully.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import threading\n", "from pytube import YouTube\n", "from moviepy.editor import VideoFileClip"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def download_video(url, output_dir):\n", "    try:\n", "        yt = YouTube(url)\n", "        video = yt.streams.filter(file_extension='mp4', progressive=True).first()\n\n", "        # Download the video\n", "        print(f\"Downloading: {yt.title}...\")\n", "        video.download(output_path=output_dir)\n", "        print(f\"Downloaded: {yt.title}\")\n", "    except Exception as e:\n", "        print(f\"Error downloading {url}: {e}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_to_audio(video_path, output_dir):\n", "    try:\n", "        video_clip = VideoFileClip(video_path)\n", "        audio_clip = video_clip.audio\n\n", "        # Generate the output audio file name\n", "        audio_file = os.path.join(output_dir, os.path.splitext(os.path.basename(video_path))[0] + \".mp3\")\n\n", "        # Convert and save the audio file\n", "        print(f\"Converting to audio: {video_path}...\")\n", "        audio_clip.write_audiofile(audio_file)\n", "        print(f\"Converted to audio: {audio_file}\")\n\n", "        # Close the video and audio clips\n", "        audio_clip.close()\n", "        video_clip.close()\n", "    except Exception as e:\n", "        print(f\"Error converting {video_path}: {e}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    # Set the YouTube video URLs you want to download\n", "    video_urls = [\n", "        \"https://www.youtube.com/watch?v=VIDEO_ID_1\",\n", "        \"https://www.youtube.com/watch?v=VIDEO_ID_2\",\n", "        # Add more video URLs here...\n", "    ]\n\n", "    # Set the output directories\n", "    video_output_dir = \"videos\"\n", "    audio_output_dir = \"audios\"\n\n", "    # Create output directories if they don't exist\n", "    os.makedirs(video_output_dir, exist_ok=True)\n", "    os.makedirs(audio_output_dir, exist_ok=True)\n\n", "    # Download videos using multithreading\n", "    download_threads = []\n", "    for url in video_urls:\n", "        t = threading.Thread(target=download_video, args=(url, video_output_dir))\n", "        t.start()\n", "        download_threads.append(t)\n\n", "    # Wait for all download threads to finish\n", "    for t in download_threads:\n", "        t.join()\n\n", "    # Convert videos to audio using multithreading\n", "    convert_threads = []\n", "    for video_file in os.listdir(video_output_dir):\n", "        video_path = os.path.join(video_output_dir, video_file)\n", "        t = threading.Thread(target=convert_to_audio, args=(video_path, audio_output_dir))\n", "        t.start()\n", "        convert_threads.append(t)\n\n", "    # Wait for all convert threads to finish\n", "    for t in convert_threads:\n", "        t.join()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues12"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import seaborn as sb\n", "from sklearn import preprocessing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set the number of rows and columns for the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_rows = 100\n", "num_columns = 30"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a random DataFrame with values between 1 and 200"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.random.randint(1, 201, size=(num_rows, num_columns))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create column names "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [f\"Column_{i+1}\" for i in range(num_columns)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the pandas DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.DataFrame(data, columns=column_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display the first few rows of the DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["i)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.replace(np.arange(10,61),np.nan,inplace=True)\n", "Nan_count = df.isna().sum().sum()\n", "print(Nan_count)\n", "print(\"(i)\")\n", "print(df.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ii)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(1,31):\n", "    newdf = df[f'Column_{i}']\n", "    avg = newdf.mean()\n", "    newdf.fillna(avg,inplace=True)\n", "print(\"(ii)\")\n", "print(df.head())\n", "#(ii)\n", "#df.corr() functions calculates pearson coeff for all cols\n", "correlations = df.corr()\n", "print(\"(iii)\")\n", "#Creating heatmap\n", "#sb.heatmap(correlations)\n", "print(correlations[correlations.abs()<=0.7])\n", "#(iv)\n", "print(\"(iv)\")\n", "#  Normalizing all the values in the dataset between 0 and 10.\n", "dataset_normalized = (df - df.min()) / (df.max() - df.min()) * 10\n", "print(dataset_normalized.head(3))\n", "#(v)\n", "print(\"(v)\")\n", "dataset_mapped = dataset_normalized.applymap(lambda i: 1 if i<=0.5 else 0)\n", "print(dataset_mapped.head(2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[33]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues13"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.cluster import KMeans, AgglomerativeClustering\n", "from scipy.cluster.hierarchy import dendrogram\n", "# Set the number of rows and columns for the dataset\n", "num_rows = 500\n", "num_columns = 10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.zeros((num_rows, num_columns))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Columns 1-4: Random values between -10 and 10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data[:, 0:4] = np.random.uniform(-10, 10, size=(num_rows, 4))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Columns 5-8: Random values between 10 and 20"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data[:, 4:8] = np.random.uniform(10, 20, size=(num_rows, 4))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Columns 9-10: Random values between -100 and 100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data[:, 8:] = np.random.uniform(-100, 100, size=(num_rows, 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create column names"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["column_names = [f\"Column_{i+1}\" for i in range(num_columns)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the pandas DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.DataFrame(data, columns=column_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display the first few rows of the DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df.head(3)) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["-means clustering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["wcss = []\n", "for i in range(1,11):\n", "    km = KMeans(n_clusters=i)\n", "    km.fit_predict(df)\n", "    wcss.append(km.inertia_)\n", "print(\"Elbow curve plot\")\n", "plt.plot(range(1,11),wcss,marker='o')\n", "#Elbow plot done to figure out the number of clusters\n", "#Determined 10 clusters\n", "optimal_clusters=4\n", "X = df.iloc[:,:].values #transforming data into np array for ease\n", "km = KMeans(n_clusters=optimal_clusters,random_state=42)\n", "y_means = km.fit_predict(X)\n", "# X[y_means == 0] , all the points in cluster 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[31]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the clusters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(X[y_means == 0, 0], X[y_means == 0, 1], color=\"red\", marker='o', label=\"Cluster 0\")\n", "plt.scatter(X[y_means == 1, 0], X[y_means == 1, 1], color=\"blue\", marker='o', label=\"Cluster 1\")\n", "plt.scatter(X[y_means == 2, 0], X[y_means == 2, 1], color=\"yellow\", marker='o', label=\"Cluster 2\")\n", "plt.scatter(X[y_means == 3, 0], X[y_means == 3, 1], color=\"pink\", marker='o', label=\"Cluster 3\")\n", "plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s=300, c='red', marker='*', label='Centroids')\n", "plt.xlabel('Column 1')\n", "plt.ylabel('Column 2')\n", "plt.title('K-means Clustering')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[37]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues 13 (ii)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from scipy.cluster.hierarchy import dendrogram, linkage\n", "from sklearn.cluster import AgglomerativeClustering"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hierarchical Clustering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 7))\n", "linked = linkage(df, method='ward')  # Compute the linkage matrix\n", "dendrogram_ = dendrogram(linked, truncate_mode='level', p=5)\n", "plt.title('Hierarchical Clustering Dendrogram')\n", "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimal_hierarchical_k = 4\n", "hierarchical_clustering = AgglomerativeClustering(n_clusters=optimal_hierarchical_k)\n", "df['Hierarchical_Cluster'] = hierarchical_clustering.fit_predict(df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[38]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ues14<br>\n", "Question 14"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)\n", "dataset = pd.DataFrame(np.random.randint(-100, 101, size=(600, 15)), columns=[f'col{i}' for i in range(1, 16)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["a) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(dataset['col5'], dataset['col6'])\n", "plt.xlabel('Column 5')\n", "plt.ylabel('Column 6')\n", "plt.title('Scatter Plot: Column 5 vs. Column 6')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["b)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset.hist(figsize=(12, 10), bins=20)\n", "plt.suptitle('Histogram of Each Column', fontsize=16)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["c)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset.plot(kind='box', vert=False, figsize=(12, 6))\n", "plt.title('Box Plot of Each Column')\n", "plt.xlabel('Values')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[39]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from scipy.stats import ttest_1samp, wilcoxon, ttest_ind, ranksums"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)\n", "dataset = pd.DataFrame(np.random.uniform(5, 11, size=(500, 5)), columns=[f'col{i}' for i in range(1, 6)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["i)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t_test_results = {}\n", "for col in dataset.columns:\n", "    t_stat, p_value = ttest_1samp(dataset[col], 7.5)  # Assuming a population mean of 7.5 for testing.\n", "    t_test_results[col] = {'t-statistic': t_stat, 'p-value': p_value}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ii)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["wilcoxon_results = {}\n", "for col in dataset.columns:\n", "    statistic, p_value = wilcoxon(dataset[col] - 7.5)  # Assuming a population median of 7.5 for testing.\n", "    wilcoxon_results[col] = {'statistic': statistic, 'p-value': p_value}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["iii)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["col3 = dataset['col3']\n", "col4 = dataset['col4']\n", "two_sample_t_test = ttest_ind(col3, col4)\n", "wilcoxon_ranksums_test = ranksums(col3, col4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Results of T-Test:\")\n", "for col, results in t_test_results.items():\n", "    print(f\"Column {col}: t-statistic={results['t-statistic']}, p-value={results['p-value']}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nResults of Wilcoxon Signed Rank Test :\")\n", "for col, results in wilcoxon_results.items():\n", "    print(f\"Column {col}: statistic={results['statistic']}, p-value={results['p-value']}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nColumn 3 and Column 4 Two Sample T-Test Results:\")\n", "print(f\"t-statistic={two_sample_t_test.statistic}, p-value={two_sample_t_test.pvalue}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nWilcoxon Rank Sum Test Results for Column 3 and Column 4:\")\n", "print(f\"statistic={wilcoxon_ranksums_test.statistic}, p-value={wilcoxon_ranksums_test.pvalue}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}